<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>warehouse on</title><link>https://gohalo.github.io/cn/tags/warehouse/</link><description>Recent content in warehouse on</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 16 Oct 2024 19:39:18 +0800</lastBuildDate><atom:link href="https://gohalo.github.io/cn/tags/warehouse/index.xml" rel="self" type="application/rss+xml"/><item><title>Datafusion 使用简介</title><link>https://gohalo.github.io/cn/blog/warehouse-datafusion-introduce/</link><pubDate>Wed, 16 Oct 2024 19:39:18 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/warehouse-datafusion-introduce/</guid><description>基本上分成了 OLAP Batch Streaming
算子落盘 # 存在 spill_count 指标， spill_record_batches read_spill_as_stream
SQL # SQL 解析依赖 SQLParser 实现，在 datafusion::sql 中将 sqlparser 重新导出，有也就意味着如下两种使用方式相同。
use datafusion::sql::sqlparser::parser::ParserError; use sqlparser::parser::ParserError; 而 DataFusion 是在 SQLParser 基础上的定制化开发，可以根据场景配置不同的方言 Dialect，常见的如 MySQL、PostgreSQL 等。
Plan # LogicalPlan # 逻辑执行计划。
ExecutionPlan # 物理执行计划节点，支持流式、并行读取数据，包含了 Projection Filter Limit 算子，当执行 execute() 方法时，只是将物理执行计划生成 RecordBatchStream 算子，形成数据流算子树，当执行 collect() 操作时才开始真正的数据流动。
会通过 DefaultPhysicalPlanner 生成执行计划，也可以通过实现 PhysicalPlanner 特征扩展。最终会通过 create_physical_plan 方法将逻辑计划转换为物理计划，每个节点是 ExecutionPlan 类型。
执行计划树时，会从根节点开始执行 execute 方法，这里不会开始处理数据，而是将物理算子转换为 RecordBatchStream 类型，只有当执行类似 collect 时才会真正执行。
TableProvider # 用于自定义表或者数据源，其中核心的是 scan 函数</description></item><item><title>Hudi Schema Evolution 详解</title><link>https://gohalo.github.io/cn/blog/hudi-schema-evolution/</link><pubDate>Mon, 22 Jul 2024 19:18:25 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/hudi-schema-evolution/</guid><description/></item><item><title>Hudi 安装部署</title><link>https://gohalo.github.io/cn/blog/hudi-environment-prepare/</link><pubDate>Tue, 16 Jul 2024 19:18:25 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/hudi-environment-prepare/</guid><description>&lt;p>这里简单介绍如何部署 &lt;code>Spark&lt;/code> 相关的 &lt;code>Hudi&lt;/code> 环境。&lt;/p></description></item><item><title>Hudi 元数据表详解</title><link>https://gohalo.github.io/cn/blog/hudi-metadata-table/</link><pubDate>Thu, 23 May 2024 19:18:25 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/hudi-metadata-table/</guid><description/></item><item><title>Hudi 示例样板</title><link>https://gohalo.github.io/cn/blog/hudi-some-examples/</link><pubDate>Mon, 20 May 2024 19:18:25 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/hudi-some-examples/</guid><description/></item><item><title>TPCH 标准测试集</title><link>https://gohalo.github.io/cn/blog/benchmark-tpch-introduce/</link><pubDate>Sat, 23 Sep 2023 22:23:32 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/benchmark-tpch-introduce/</guid><description>&lt;p>由事务处理委员会提供的基准测试集。&lt;/p></description></item><item><title>StarRocks Catalog 基本介绍</title><link>https://gohalo.github.io/cn/blog/starrocks-catalog-introduce/</link><pubDate>Thu, 21 Sep 2023 22:23:32 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/starrocks-catalog-introduce/</guid><description/></item><item><title>StarRocks DDL 基本介绍</title><link>https://gohalo.github.io/cn/blog/starrocks-ddl-introduce/</link><pubDate>Thu, 21 Sep 2023 22:23:32 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/starrocks-ddl-introduce/</guid><description/></item><item><title>Spark 示例代码</title><link>https://gohalo.github.io/cn/blog/spark-example-code/</link><pubDate>Wed, 20 Sep 2023 21:15:12 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/spark-example-code/</guid><description>&lt;p>整理一些常用的 Spark 相关示例代码。&lt;/p></description></item><item><title>Hudi 常用命令</title><link>https://gohalo.github.io/cn/blog/hudi-cheatsheet/</link><pubDate>Tue, 22 Aug 2023 19:18:25 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/hudi-cheatsheet/</guid><description/></item><item><title>Arrow 内存列式数据存储格式</title><link>https://gohalo.github.io/cn/blog/warehouse-format-arrow/</link><pubDate>Wed, 09 Nov 2022 20:45:52 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/warehouse-format-arrow/</guid><description>&lt;p>定义了内存布局格式，从而允许在不同的系统之间高效地共享数据，通过减少不必要的序列化和反序列化成本，从而提高不同系统间传递数据效率。&lt;/p></description></item><item><title>AVRO 元数据格式</title><link>https://gohalo.github.io/cn/blog/warehouse-format-avro/</link><pubDate>Wed, 09 Nov 2022 20:45:52 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/warehouse-format-avro/</guid><description>&lt;p>这是一个数据序列化系统。&lt;/p></description></item><item><title>Flight 通讯协议</title><link>https://gohalo.github.io/cn/blog/warehouse-protocol-flight/</link><pubDate>Wed, 09 Nov 2022 20:45:52 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/warehouse-protocol-flight/</guid><description>&lt;p>最初 Flight 专注于 Arrow 这种列式存储格式，通过 gRPC 作底层传输优化。&lt;/p></description></item><item><title>Hudi 基本介绍</title><link>https://gohalo.github.io/cn/blog/hudi-basic-introduce/</link><pubDate>Wed, 21 Sep 2022 22:23:32 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/hudi-basic-introduce/</guid><description>&lt;p>Hadoop Updates and Incrementals, Hudi 是一个 Uber 开源的 Data Lakes 的解决方案。&lt;/p></description></item><item><title>Kerberos 基本介绍</title><link>https://gohalo.github.io/cn/blog/kerberos-basic-introduce/</link><pubDate>Wed, 21 Sep 2022 22:23:32 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/kerberos-basic-introduce/</guid><description>&lt;p>通常用于身份认证。&lt;/p></description></item><item><title>Flink 使用介绍</title><link>https://gohalo.github.io/cn/blog/flink-basic-introduce/</link><pubDate>Mon, 19 Sep 2022 21:15:12 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/flink-basic-introduce/</guid><description>&lt;p>分布式计算框架，可以对有界 (批) 和无界 (流) 数据进行处理。&lt;/p></description></item><item><title>Hudi Streamer 数据导入示例 TPCH</title><link>https://gohalo.github.io/cn/blog/hudi-streamer-example-tpch/</link><pubDate>Mon, 19 Sep 2022 21:15:12 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/hudi-streamer-example-tpch/</guid><description/></item><item><title>Hudi Streamer 简介</title><link>https://gohalo.github.io/cn/blog/hudi-streamer-usage/</link><pubDate>Mon, 19 Sep 2022 21:15:12 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/hudi-streamer-usage/</guid><description>&lt;p>提供了实时的数据倒入方式，其源端可以是 Kafka 或者文件。&lt;/p></description></item><item><title>Spark Native 加速</title><link>https://gohalo.github.io/cn/blog/spark-native-execution-engine/</link><pubDate>Mon, 19 Sep 2022 21:15:12 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/spark-native-execution-engine/</guid><description/></item><item><title>Spark 使用介绍</title><link>https://gohalo.github.io/cn/blog/spark-basic-introduce/</link><pubDate>Mon, 19 Sep 2022 21:15:12 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/spark-basic-introduce/</guid><description>&lt;p>开源的集群运算框架，与 Hadoop 在执行 MapReduce 需要落盘不同，Spark 的数据会尽量在内存中进行计算。&lt;/p></description></item><item><title>HDFS 基本介绍</title><link>https://gohalo.github.io/cn/blog/hdfs-basic-introduce/</link><pubDate>Thu, 21 Jul 2022 22:23:32 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/hdfs-basic-introduce/</guid><description>&lt;p>Hadoop Distributed File System, HDFS&lt;/p></description></item><item><title>Kafka 常用命令</title><link>https://gohalo.github.io/cn/blog/kafka-commands-cheatsheet/</link><pubDate>Wed, 22 Jun 2022 21:23:32 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/kafka-commands-cheatsheet/</guid><description>&lt;p>整理 Kafka 常用的命令，可以用于快速查询。&lt;/p></description></item><item><title>Hive 基本介绍</title><link>https://gohalo.github.io/cn/blog/hive-basic-introduce/</link><pubDate>Tue, 21 Jun 2022 22:23:32 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/hive-basic-introduce/</guid><description>&lt;p>Hive 是由 Facebook 开发建立在 Hadoop 之上的数据仓库，初衷是为了减少复杂 MR 程序的编写工作，其本身不存储和处理数据，依赖 HDFS 存储数据和 MR 处理数据，有类 SQL 语言的 HiveQL，其不完全支持 SQL 标准，例如不支持更新、索引、事务，子查询和连接操作也有很多限制。&lt;/p></description></item><item><title>Parquet 文件格式详解</title><link>https://gohalo.github.io/cn/blog/warehouse-format-parquet/</link><pubDate>Wed, 01 Dec 2021 18:19:15 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/warehouse-format-parquet/</guid><description/></item><item><title>ORC 文件格式详解</title><link>https://gohalo.github.io/cn/blog/warehouse-format-orc/</link><pubDate>Tue, 05 Oct 2021 18:19:15 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/warehouse-format-orc/</guid><description/></item><item><title>Kafka 基本介绍</title><link>https://gohalo.github.io/cn/blog/kafka-basic-introduce/</link><pubDate>Fri, 22 Jun 2018 21:23:32 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/kafka-basic-introduce/</guid><description>&lt;p>Apache Kafka 最初由 LinkedIn 开发，通过 Scala 和 Java 编写的一个分布式消息系统，在 2011 年成为 Apache 的孵化项目，随后于 2012 年成为 Apache 的主要项目之一。&lt;/p>
&lt;p>因为其可扩展、高吞吐、高可用等特性被广泛应用在大规模的消息处理场景中，一些常见的流处理工具都支持与 Kafka 的集成。&lt;/p></description></item><item><title>ZooKeeper 基本介绍</title><link>https://gohalo.github.io/cn/blog/zookeeper-basic-introduce/</link><pubDate>Fri, 22 Jun 2018 21:23:32 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/zookeeper-basic-introduce/</guid><description/></item><item><title>AirFlow 工作流简介</title><link>https://gohalo.github.io/cn/blog/airflow-dac-introduce/</link><pubDate>Sun, 19 Nov 2017 21:18:34 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/airflow-dac-introduce/</guid><description>&lt;p>AirFlow 一个用于编排复杂计算工作流和数据处理流水线的开源工具，通常可以解决一些复杂超长 Cron 脚本任务或者大数据的批量处理任务。&lt;/p>
&lt;p>其工作流的设计是基于有向非循环图 (Directed Acyclical Graphs, DAG) ，用于设置任务依赖关系和时间调度。&lt;/p>
&lt;p>简单来说，在编写工作流时，尽量考虑如何将一个大型的任务拆分为多个可独立执行的原子任务，再将这些任务合并为一个逻辑整体。&lt;/p>
&lt;p>这里简单介绍一些常见的基本概念及其使用方法。&lt;/p></description></item><item><title>【专题】数据仓库</title><link>https://gohalo.github.io/cn/blog/topic-warehouse-introduce/</link><pubDate>Tue, 21 Dec 2010 21:18:34 +0800</pubDate><guid>https://gohalo.github.io/cn/blog/topic-warehouse-introduce/</guid><description/></item></channel></rss>