<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>贝叶斯简介 | GoHalo</title><link rel=apple-touch-icon sizes=180x180 href=https://gohalo.github.io/favicon/apple-touch-icon.png><link rel=icon href=https://gohalo.github.io/favicon/favicon.ico sizes=any><link rel=icon type=image/png sizes=32x32 href=https://gohalo.github.io/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://gohalo.github.io/favicon/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://gohalo.github.io/favicon/site.webmanifest><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=google-site-verification content="p7jJ5d3kF9yxRhpIo5GgHXAZ1ATKVyZhV2kf6mEGOv0"><meta name=description content="贝叶斯定理 (Bayes&amp;rsquo; Theorem) 是英国数学家 托马斯·贝叶斯 (Thomas Bayes) 在 1763 年发表的一篇论文中首次提出；而贝叶斯推断 (Bayesian Inference) 是贝叶斯定理的一种应用，是一种统计学方法，用来估计统计量的某些性质。
这里简单介绍其基本概念。
"><link rel=stylesheet href=https://gohalo.github.io/font-awesome/css/font-awesome.min.css><link rel=stylesheet href=/css/syntax.min.c70103877c799b924f50023b6b01eca010d7e2808885a74f9ea662cc47379ae1.css integrity="sha256-xwEDh3x5m5JPUAI7awHsoBDX4oCIhadPnqZizEc3muE=" crossorigin=anonymous><link rel=stylesheet href=/css/main.min.c4814ac9dc5fab259f313a787ded4f8e.css integrity="md5-xIFKydxfqyWfMTp4fe1Pjg==" crossorigin=anonymous><link rel=stylesheet href=https://gohalo.github.io/katex/katex.min.css><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><style type=text/css>.main p{text-indent:2em}.main li p{text-indent:0}</style><noscript><style>img.lazyload{display:none}</style></noscript></head><body><div class=sticky-top><div class=header-bar></div><nav class="navbar navbar-expand-lg navbar-light bg-light"><div class="container-xxl flex-wrap flex-lg-nowrap" aria-label="Main navigation"><a class="navbar-brand order-0" href=/cn aria-label=GoHalo>GoHalo</a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-expanded=false>项目</a><ul class=dropdown-menu aria-labelledby=navbarDropdown><li><a class=dropdown-item href=/cn/project/bastion/>Bastion</a></li><li><a class="dropdown-item disabled" href=/cn/project/bootserver/>BootServer</a></li></ul></li><li class=nav-item><a class=nav-link aria-current=page href=/cn/blog/>博客</a></li><li class=nav-item><a class=nav-link aria-current=page href=/cn/blog/archives/>归档</a></li><li class=nav-item><a class=nav-link aria-current=page href=/cn/blog/tags/>标签</a></li><li class=nav-item><a class=nav-link aria-current=page href=/cn/slide/>幻灯片</a></li><li class=nav-item><a class=nav-link aria-current=page href=/cn/docs/>文档</a></li></ul><hr class="text-black-50 my-4 d-lg-none"><div class=dropdown><button class="btn dropdown-toggle" id=header-languages data-bs-toggle=dropdown aria-expanded=false data-bs-display=static>
中文</button><ul class="dropdown-menu dropdown-menu-lg-end me-lg-2 shadow rounded border-0" aria-labelledby=header-languages><li><a class=dropdown-item rel=alternate href=https://gohalo.github.io/en hreflang=en lang=en>English</a></li></ul></div><ul class="nav flex-column flex-lg-row"><li class=nav-item><a class="nav-link social-link" href=/cn/about><i class="fa fa-user" aria-hidden=true></i></a></li><li class=nav-item><a class="nav-link social-link" href=https://github.com/gohalo title=GitHub><i class="fa fa-github-alt" aria-hidden=true></i></a></li><li class=nav-item><button id=mode class="btn nav-link social-link" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><i class="fa fa-star" aria-hidden=true></i></span>
<span class=toggle-light><i class="fa fa-cog" aria-hidden=true></i></span></button></li></ul></div></div></nav></div><div class="main container-xxl" role=document><div class="blog row"><div class="col-md-12 col-xl-9 mt-4"><div class=header><h1>贝叶斯简介</h1><div class="meta mb-3"><i class="fa fa-calendar" aria-hidden=true></i>
<span class=mx-2>2017-01-20</span>
<i class="fa fa-tags" aria-hidden=true></i>
<a class=text-body href=https://gohalo.github.io/cn/tags/ai/ role=button>ai</a></div></div><hr><div class=content><p>贝叶斯定理 (Bayes&rsquo; Theorem) 是英国数学家 托马斯·贝叶斯 (Thomas Bayes) 在 1763 年发表的一篇论文中首次提出；而贝叶斯推断 (Bayesian Inference) 是贝叶斯定理的一种应用，是一种统计学方法，用来估计统计量的某些性质。</p><p>这里简单介绍其基本概念。</p><a class=anchor id=简介></a><h1>简介 <a href=#%e7%ae%80%e4%bb%8b aria-hidden=true>#</a></h1><p>在统计学界一直有两种观点：A) 频率学派；B) 贝叶斯学派。</p><p>贝叶斯推断与统计学的推断方法不同，是建立在主观判断的基础上，也就是说，可以不需要客观证据，先估计一个值，然后根据实际结果不断修正。正是因为它的主观性太强，曾经遭到许多统计学家的诟病，很长时间内无法广泛应用。</p><p>在计算机获得广泛发展后，人们也逐渐意识到，许多统计量是无法事先进行客观判断的，而利用互联网中的大型数据集，可以不断更新完善模型，从而为应用贝叶斯推断创造了条件。</p><p>贝叶斯学派的思想是用数据来更新特定假设的概率。</p><a class=anchor id=贝叶斯定理></a><h1>贝叶斯定理 <a href=#%e8%b4%9d%e5%8f%b6%e6%96%af%e5%ae%9a%e7%90%86 aria-hidden=true>#</a></h1><p>贝叶斯定理实际上是条件概率的一种推断。</p><a class=anchor id=条件概率-conditional-probability></a><h2>条件概率 Conditional Probability <a href=#%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87-conditional-probability aria-hidden=true>#</a></h2><p>是指在 <strong>已知</strong> 事件 A 发生的情况下，此时事件 B 发生的概率，这里用 <code>P(B|A)</code> 来表示，此时的表达式可以表示为 <code>P(B|A)=P(AB)/P(A)</code> 。</p><p>例如，将一枚硬币抛掷两次，其中事件 A 为 &ldquo;至少一次为正面(H)&rdquo; ，事件 B 为 &ldquo;两次掷出同面&rdquo; ，那么已知事件 A 发生的条件下事件 B 发生的概率。</p><p>这里的样本空间为 <code>S={HH, HT, TH, TT} A={HH, HT, TH} B={HH, TT}</code> 那么如果事件 A 已经发生，事件 B 发生的概率为 <code>P(B|A)=[1/4]/[3/4]=1/3</code> 。</p><p>需要注意的是，在这些定义中 A 与 B 之间不一定有因果或者时间序列关系，A 可能会先于 B 发生，也可能相反，也可能二者同时发生；A 可能会导致 B 的发生，也可能相反，也可能二者之间根本就没有因果关系。</p><a class=anchor id=贝叶斯公式></a><h2>贝叶斯公式 <a href=#%e8%b4%9d%e5%8f%b6%e6%96%af%e5%85%ac%e5%bc%8f aria-hidden=true>#</a></h2><p>通过条件概率，就可以得到乘法公式，也就是 <code>P(AB)=P(A|B)P(B)=P(B|A)P(A)</code> 。</p><p>进而可以得出，贝叶斯最常用的公式，如下：</p><p>$$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$</p><p>这个看起来很简单，无非就是条件概率和联合概率公式的组合，其中：</p><ul><li><code>P(A)</code> 是先验概率或者边缘概率，之所以称为 &ldquo;先验&rdquo; 是因为不考虑任何与 B 相关的因素，完全独立计算，可以通过大数据统计得到。</li><li><code>P(A|B)</code> 已知 B 发生后 A 发生的概率，称为 A 的后验概率。</li><li><code>P(B)</code> 是先验概率或者边缘概率，也被称为标准化常量 (Normalized Constant)。</li></ul><p><img alt=bayes src=images/bayes-equation.jpg class="mx-auto d-block"></p><a class=anchor id=贝叶斯推断></a><h1>贝叶斯推断 <a href=#%e8%b4%9d%e5%8f%b6%e6%96%af%e6%8e%a8%e6%96%ad aria-hidden=true>#</a></h1><p>为了方便计算后验概率，这里采用共轭先验的方法来简化后验的计算。</p><a class=anchor id=先验概率></a><h2>先验概率 <a href=#%e5%85%88%e9%aa%8c%e6%a6%82%e7%8e%87 aria-hidden=true>#</a></h2><p>这里仍然以投掷硬币为例，开始认为正面朝上的概率服从 Beta 分布，Beta 分布能产生一个 $(0, 1)$ 之间的随机数，也就是说先验概率为 Beta 分布。</p><p>$$f(x;\alpha,\beta)=\frac{1}{B(\alpha, \beta)} x^{\alpha - 1} (1 - x)^{\beta - 1}$$</p><p>开始假设 $\alpha=\beta=1$，那么此时 Beta 分布退化为一个均匀分布。接着不断投硬币，记录好每次投掷结果，然后根据结果再来计算此时正面朝上的概率。</p><a class=anchor id=似然函数></a><h2>似然函数 <a href=#%e4%bc%bc%e7%84%b6%e5%87%bd%e6%95%b0 aria-hidden=true>#</a></h2><p>也就是在 $n$ 次试验中，有 $k$ 次朝上的概率，显然满足二项分布，可以表示为。</p><p>$$P(x|\theta)=C_n^k \theta^k (1 - \theta)^{n-k}$$</p><a class=anchor id=后验概率></a><h2>后验概率 <a href=#%e5%90%8e%e9%aa%8c%e6%a6%82%e7%8e%87 aria-hidden=true>#</a></h2><p>这里直接通过计算求解。</p><p>$$
\begin{align}
P(\theta|x) &= \frac{P(x|\theta)P(\theta)}{P(x)} \propto P(x|\theta)P(\theta) \
&= \left ( C_n^k \theta^k (1 - \theta)^{n-k} \right ) \left(\frac{1}{B(\alpha, \beta)} \theta^{\alpha - 1} (1 - \theta)^{\beta - 1}\right) \
&=\frac{C_n^k}{B(\alpha,\beta)} \theta^{(k+\alpha)-1}\left(1-\theta\right)^{(n-k+\beta)-1} \
&\propto \frac{1}{B\left(k+\alpha, n-k+\beta\right)} \theta^{(k+\alpha)-1} \left(1-\theta\right)^{(n-k+\beta)-1}
\end{align}
$$</p><p>可以看到，后验概率也是 Beta 分布，可以很方便的通过先验 Beta 分布来计算出后验概率。</p><a class=anchor id=试验></a><h2>试验 <a href=#%e8%af%95%e9%aa%8c aria-hidden=true>#</a></h2><p>对应的试验如下，也就是，随着试验次数的增加，正面朝上的概率越来越接近 $0.5$ 。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>scipy.stats</span> <span class=k>as</span> <span class=nn>stats</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Arguments for prior Beta distribution</span>
</span></span><span class=line><span class=cl><span class=p>(</span><span class=n>alpha</span><span class=p>,</span> <span class=n>beta</span><span class=p>)</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create a list of the number of coin tosses (&#34;Bernoulli trials&#34;)</span>
</span></span><span class=line><span class=cl><span class=n>number_of_trials</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>500</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Conduct 500 coin tosses and output into a list of 0s and 1s</span>
</span></span><span class=line><span class=cl><span class=c1># where 0 represents a tail and 1 represents a head</span>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>bernoulli</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=n>number_of_trials</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Discretise the x-axis into 100 separate plotting points</span>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Loops over the number_of_trials list to continually add</span>
</span></span><span class=line><span class=cl><span class=c1># more coin toss data. For each new set of data, we update</span>
</span></span><span class=line><span class=cl><span class=c1># our (current) prior belief to be a new posterior. This is</span>
</span></span><span class=line><span class=cl><span class=c1># carried out using what is known as the Beta-Binomial model.</span>
</span></span><span class=line><span class=cl><span class=c1># For the time being, we won&#39;t worry about this too much. It</span>
</span></span><span class=line><span class=cl><span class=c1># will be the subject of a later article!</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>N</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>number_of_trials</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=c1># Accumulate the total number of heads for this</span>
</span></span><span class=line><span class=cl>	<span class=c1># particular Bayesian update</span>
</span></span><span class=line><span class=cl>	<span class=n>heads</span> <span class=o>=</span> <span class=n>data</span><span class=p>[:</span><span class=n>N</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=c1># Create an axes subplot for each update</span>
</span></span><span class=line><span class=cl>	<span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>number_of_trials</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s2>&#34;</span><span class=si>%s</span><span class=s2> trials, </span><span class=si>%s</span><span class=s2> heads&#34;</span> <span class=o>%</span> <span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>heads</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=c1># Add labels to both axes and hide labels on y-axis</span>
</span></span><span class=line><span class=cl>	<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&#34;$P(H)$, Probability of Heads&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&#34;Density&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=n>i</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=n>plt</span><span class=o>.</span><span class=n>ylim</span><span class=p>([</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>	<span class=n>plt</span><span class=o>.</span><span class=n>setp</span><span class=p>(</span><span class=n>ax</span><span class=o>.</span><span class=n>get_yticklabels</span><span class=p>(),</span> <span class=n>visible</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=c1># Create and plot a Beta distribution to represent the</span>
</span></span><span class=line><span class=cl>	<span class=c1># posterior belief in fairness of the coin.</span>
</span></span><span class=line><span class=cl>	<span class=n>y</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>beta</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>alpha</span> <span class=o>+</span> <span class=n>heads</span><span class=p>,</span> <span class=n>beta</span> <span class=o>+</span> <span class=n>N</span> <span class=o>-</span> <span class=n>heads</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;observe </span><span class=si>%d</span><span class=s2> tosses,</span><span class=se>\n</span><span class=s2> </span><span class=si>%d</span><span class=s2> heads&#34;</span> <span class=o>%</span> <span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>heads</span><span class=p>))</span>
</span></span><span class=line><span class=cl>	<span class=n>plt</span><span class=o>.</span><span class=n>fill_between</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;#aaaadd&#34;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Expand plot to cover full width/height and show it</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p><img alt="bayesian example" src=images/bayesian-statistics-beta-bernoulli-example.png class="mx-auto d-block"></p><a class=anchor id=案例></a><h1>案例 <a href=#%e6%a1%88%e4%be%8b aria-hidden=true>#</a></h1><p>很多时候示例是最显而易见的讲解方式。</p><a class=anchor id=案例-1></a><h3>案例 #1 <a href=#%e6%a1%88%e4%be%8b-1 aria-hidden=true>#</a></h3><p>一个学校里有 <code>60%</code> 男生和 <code>40%</code> 女生，女生穿裤子的人数和穿裙子的人数相等，所有男生穿裤子。一个人在远处随机看到了一个穿裤子的学生，那么这个学生是女生的概率是多少？</p><p>利用贝叶斯定理，假设事件 A 是看到女生，事件 B 是看到一个穿裤子的学生，那么我们所要计算的是 <code>P(A|B)</code>。</p><ul><li><code>P(A)</code> 是忽略其它因素，看到女生的概率，在这里是 <code>40%</code>；</li><li><code>P(A')</code> 是忽略其它因素，看到不是女生(也就是看到男生)的概率，在这里是 <code>60%</code>；</li><li><code>P(B|A)</code> 是女生穿裤子的概率，在这里是 <code>50%</code>；</li><li><code>P(B|A')</code> 是男生穿裤子的概率，在这里是 <code>100%</code>；</li><li><code>P(B)</code> 是忽略其它因素，直接考虑学生穿裤子的概率，<code>P(B) = P(B|A)P(A) + P(B|A')P(A')</code>，在这里是 <code>0.5*0.4 + 1*0.6 = 0.8</code> ；</li></ul><p>那么根据贝叶斯公式，可以计算得到，也就是 <code>P(A|B) = (0.5 * 0.4)/(0.8) = 0.25</code> 。</p><a class=anchor id=贝叶斯过滤器></a><h3>贝叶斯过滤器 <a href=#%e8%b4%9d%e5%8f%b6%e6%96%af%e8%bf%87%e6%bb%a4%e5%99%a8 aria-hidden=true>#</a></h3><p>对于垃圾邮件来说，传统使用较多的是关键词，但是很容易误判，2002 年 Paul Graham 提出使用 &ldquo;贝叶斯推断&rdquo; 过滤垃圾邮件，取得了很好的效果，据说 1000 封垃圾邮件可以过滤掉 995 封，且没有一个误判。</p><p>另外，这种过滤器还具有学习能力，会根据新收到的邮件，不断调整，收到的垃圾邮件越多，它的准确率就越高。</p></div></div><div class="sidebar col-xl-3 mt-2"><div id=toc class=position-fixed><nav id=TableOfContents><ul><li><a href=#简介>简介</a></li><li><a href=#贝叶斯定理>贝叶斯定理</a><ul><li><a href=#条件概率-conditional-probability>条件概率 Conditional Probability</a></li><li><a href=#贝叶斯公式>贝叶斯公式</a></li></ul></li><li><a href=#贝叶斯推断>贝叶斯推断</a><ul><li><a href=#先验概率>先验概率</a></li><li><a href=#似然函数>似然函数</a></li><li><a href=#后验概率>后验概率</a></li><li><a href=#试验>试验</a></li></ul></li><li><a href=#案例>案例</a><ul><li></li></ul></li></ul></nav></div></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class=text-center>Built by GoHalo, generated with <a class=text-muted href=https://gohugo.io>Hugo</a>, and hosted on GitHub Pages</div></div><div class=row><div class=text-center>Copyright © 2013-2025 GoHalo. All Rights Reserved.</div></div></div></footer><script src=https://gohalo.github.io/bootstrap/js/bootstrap.bundle.min.js></script>
<script src=https://gohalo.github.io/katex/katex.min.js></script>
<script src=https://gohalo.github.io/katex/contrib/auto-render.min.js onload=renderMathInElement(document.body) defer></script>
<script src=/main.b9cbcb174709877512d64e24f297f66a40c8d91c9a81128cb04bdd7b10247df8.js integrity="sha256-ucvLF0cJh3US1k4k8pf2akDI2RyagRKMsEvdexAkffg=" crossorigin=anonymous></script>
<a href=# class="btn btn-light btn-lg backtop" title=返回顶部><i class="fa fa-angle-double-up" aria-hidden=true></i></a></body></html>