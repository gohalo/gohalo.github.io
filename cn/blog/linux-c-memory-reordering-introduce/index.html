<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Memory Reordering 简析 | GoHalo</title><link rel=apple-touch-icon sizes=180x180 href=https://gohalo.github.io/favicon/apple-touch-icon.png><link rel=icon href=https://gohalo.github.io/favicon/favicon.ico sizes=any><link rel=icon type=image/png sizes=32x32 href=https://gohalo.github.io/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://gohalo.github.io/favicon/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://gohalo.github.io/favicon/site.webmanifest><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=google-site-verification content="p7jJ5d3kF9yxRhpIo5GgHXAZ1ATKVyZhV2kf6mEGOv0"><meta name=description content="以 C 语言为例，在编写完源代码之后，需要经过编译，然后在 CPU 上运行，为了提高代码的执行效率，在编译阶段和运行阶段会执行乱序优化，但同时也带来了一些副作用。
这里简单介绍内存乱序的基本概念。
"><link rel=stylesheet href=https://gohalo.github.io/font-awesome/css/font-awesome.min.css><link rel=stylesheet href=/css/syntax.min.c70103877c799b924f50023b6b01eca010d7e2808885a74f9ea662cc47379ae1.css integrity="sha256-xwEDh3x5m5JPUAI7awHsoBDX4oCIhadPnqZizEc3muE=" crossorigin=anonymous><link rel=stylesheet href=/css/main.min.c4814ac9dc5fab259f313a787ded4f8e.css integrity="md5-xIFKydxfqyWfMTp4fe1Pjg==" crossorigin=anonymous><style type=text/css>.main p{text-indent:2em}.main li p{text-indent:0}</style><noscript><style>img.lazyload{display:none}</style></noscript></head><body><div class=sticky-top><div class=header-bar></div><nav class="navbar navbar-expand-lg navbar-light bg-light"><div class="container-xxl flex-wrap flex-lg-nowrap" aria-label="Main navigation"><a class="navbar-brand order-0" href=/cn aria-label=GoHalo>GoHalo</a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-expanded=false>项目</a><ul class=dropdown-menu aria-labelledby=navbarDropdown><li><a class=dropdown-item href=/cn/project/bastion/>Bastion</a></li><li><a class="dropdown-item disabled" href=/cn/project/bootserver/>BootServer</a></li></ul></li><li class=nav-item><a class=nav-link aria-current=page href=/cn/blog/>博客</a></li><li class=nav-item><a class=nav-link aria-current=page href=/cn/blog/archives/>归档</a></li><li class=nav-item><a class=nav-link aria-current=page href=/cn/blog/tags/>标签</a></li><li class=nav-item><a class=nav-link aria-current=page href=/cn/slide/>幻灯片</a></li><li class=nav-item><a class=nav-link aria-current=page href=/cn/docs/>文档</a></li></ul><hr class="text-black-50 my-4 d-lg-none"><div class=dropdown><button class="btn dropdown-toggle" id=header-languages data-bs-toggle=dropdown aria-expanded=false data-bs-display=static>
中文</button><ul class="dropdown-menu dropdown-menu-lg-end me-lg-2 shadow rounded border-0" aria-labelledby=header-languages><li><a class=dropdown-item rel=alternate href=https://gohalo.github.io/en hreflang=en lang=en>English</a></li></ul></div><ul class="nav flex-column flex-lg-row"><li class=nav-item><a class="nav-link social-link" href=/cn/about><i class="fa fa-user" aria-hidden=true></i></a></li><li class=nav-item><a class="nav-link social-link" href=https://github.com/gohalo title=GitHub><i class="fa fa-github-alt" aria-hidden=true></i></a></li><li class=nav-item><button id=mode class="btn nav-link social-link" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><i class="fa fa-star" aria-hidden=true></i></span>
<span class=toggle-light><i class="fa fa-cog" aria-hidden=true></i></span></button></li></ul></div></div></nav></div><div class="main container-xxl" role=document><div class="blog row"><div class="col-md-12 col-xl-9 mt-4"><div class=header><h1>Memory Reordering 简析</h1><div class="meta mb-3"><i class="fa fa-calendar" aria-hidden=true></i>
<span class=mx-2>2019-02-01</span>
<i class="fa fa-tags" aria-hidden=true></i>
<a class=text-body href=https://gohalo.github.io/cn/tags/language/ role=button>language</a>
<a class=text-body href=https://gohalo.github.io/cn/tags/c/cpp/ role=button>c/cpp</a></div></div><hr><div class=content><p>以 C 语言为例，在编写完源代码之后，需要经过编译，然后在 CPU 上运行，为了提高代码的执行效率，在编译阶段和运行阶段会执行乱序优化，但同时也带来了一些副作用。</p><p>这里简单介绍内存乱序的基本概念。</p><p><img alt="compiler harderware" src=images/memory-reordering-compiler-hardware.png class="mx-auto d-block"></p><a class=anchor id=简介></a><h1>简介 <a href=#%e7%ae%80%e4%bb%8b aria-hidden=true>#</a></h1><p>简单来说，编译器的开发者和处理器的制造商会遵循一条所谓的中心内存排序原则，也就是 &ldquo;不能改变单线程程序的行为&rdquo; 。</p><p>因为这一原则，在单线程代码中可以忽略内存乱序，即使在多线程程序中，如果使用了 Mutex、Semaphore 等同步机制，那么仍然可以防止乱序，只有在使用 Lock-Free 时，此时的内存在不受任何互斥保护下被多个线程共享，那么内存乱序的影响才会被看到。</p><p>会发生什么样的乱序，是与编译工具和 CPU 相关的。</p><p>一般把编译阶段产生的乱序称为 Compiler Reordering，也即 Software Memory Reordering；把运行阶段产生的乱序称为 CPU Memory Reordering，也叫做 Hardware Memory Reordering，这两者之间区别很大。</p><a class=anchor id=编译乱序></a><h1>编译乱序 <a href=#%e7%bc%96%e8%af%91%e4%b9%b1%e5%ba%8f aria-hidden=true>#</a></h1><p>编译乱序就是在编译阶段，编译器为了优化程序的执行效率，自动将内存操作指令重排，从而使得读写内存的指令与程序定义的操作顺序不一致。</p><p>这也就意味着，不同的编译器，甚至不同的参数，最终编译的结果也会有所出入。</p><p>例如，对于如下简单的 c 程序。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>int</span> <span class=n>A</span><span class=p>,</span> <span class=n>B</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>foobar</span><span class=p>(</span><span class=kt>void</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>A</span> <span class=o>=</span> <span class=n>B</span> <span class=o>+</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=n>B</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>通过命令编译 <code>gcc -S foobar.c</code> 得到汇编程序 (语法为 AT&amp;T 可以使用 <code>-masm=intel</code> 指定为 Intel 语法)，打开 foobar.s 查看汇编代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-asm data-lang=asm><span class=line><span class=cl><span class=nf>movl</span>	<span class=no>B</span><span class=p>(</span><span class=nv>%rip</span><span class=p>),</span> <span class=nv>%eax</span>
</span></span><span class=line><span class=cl><span class=nf>addl</span>	<span class=no>$1</span><span class=p>,</span> <span class=nv>%eax</span>
</span></span><span class=line><span class=cl><span class=nf>movl</span>	<span class=nv>%eax</span><span class=p>,</span> <span class=no>A</span><span class=p>(</span><span class=nv>%rip</span><span class=p>)</span>     <span class=c1>// store to A
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>movl</span>	<span class=no>$0</span><span class=p>,</span> <span class=no>B</span><span class=p>(</span><span class=nv>%rip</span><span class=p>)</span>       <span class=c1>// store to B
</span></span></span></code></pre></div><p>可以看到，上述的汇编代码严格按照程序中定义顺序执行 load 和 store 指令，即先保存变量 a 的值，后保存变量 b 的值，也就是说，这段代码并没有产生任何内存乱序。</p><p>接下来通过 <code>gcc -O2 -S foobar.c</code> 重新编译 foobar.c ，其中相关代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-asm data-lang=asm><span class=line><span class=cl><span class=nf>movl</span>	<span class=no>B</span><span class=p>(</span><span class=nv>%rip</span><span class=p>),</span> <span class=nv>%eax</span>
</span></span><span class=line><span class=cl><span class=nf>movl</span>	<span class=no>$0</span><span class=p>,</span> <span class=no>B</span><span class=p>(</span><span class=nv>%rip</span><span class=p>)</span>       <span class=c1>// store to B
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>addl</span>	<span class=no>$1</span><span class=p>,</span> <span class=nv>%eax</span>
</span></span><span class=line><span class=cl><span class=nf>movl</span>	<span class=nv>%eax</span><span class=p>,</span> <span class=no>A</span><span class=p>(</span><span class=nv>%rip</span><span class=p>)</span>     <span class=c1>// store to A
</span></span></span></code></pre></div><p>可以看到，汇编指令先执行变量 <code>b = 0</code> 的存储，之后才执行 <code>a = b + 1</code> 的操作，表明变量 a 和 b 的 store 操作没有按照他们在程序中定义的顺序来执行，即产生了 Compiler Reordering。</p><p>之所以这么优化，是因为读一个在内存中而不是在 Cache 中的共享变量需要很多周期，所以编译器就 &ldquo;自作聪明&rdquo; 的让读操作先执行，从而隐藏掉一些指令执行的 Latency，提高程序的性能。</p><p>很显然，在单线程的场景下，最终仍然会得到 <code>a = 1</code> 以及 <code>b = 0</code>，也就是说，即乱序没有影响单线程的执行结果，这也是最基本的原则。</p><a class=anchor id=防止乱序></a><h2>防止乱序 <a href=#%e9%98%b2%e6%ad%a2%e4%b9%b1%e5%ba%8f aria-hidden=true>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>int</span> <span class=n>A</span><span class=p>,</span> <span class=n>B</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>foobar</span><span class=p>(</span><span class=kt>void</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>A</span> <span class=o>=</span> <span class=n>B</span> <span class=o>+</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>asm</span> <span class=k>volatile</span><span class=p>(</span><span class=s>&#34;&#34;</span> <span class=o>:::</span> <span class=s>&#34;memory&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=n>B</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>然后，通过 <code>gcc -O2 -S foobar.c</code> 重新编译 foobar.c ，其中相关代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-asm data-lang=asm><span class=line><span class=cl><span class=nf>movl</span>	<span class=no>B</span><span class=p>(</span><span class=nv>%rip</span><span class=p>),</span> <span class=nv>%eax</span>
</span></span><span class=line><span class=cl><span class=nf>addl</span>	<span class=no>$1</span><span class=p>,</span> <span class=nv>%eax</span>
</span></span><span class=line><span class=cl><span class=nf>movl</span>	<span class=nv>%eax</span><span class=p>,</span> <span class=no>A</span><span class=p>(</span><span class=nv>%rip</span><span class=p>)</span>  <span class=c1>// store to A
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>movl</span>	<span class=no>$0</span><span class=p>,</span> <span class=no>B</span><span class=p>(</span><span class=nv>%rip</span><span class=p>)</span>    <span class=c1>// store to B
</span></span></span></code></pre></div><a class=anchor id=cpu-乱序></a><h1>CPU 乱序 <a href=#cpu-%e4%b9%b1%e5%ba%8f aria-hidden=true>#</a></h1><p>关于 x86 的内存模型可能出现的乱序可以参考 <a href=http://www.cs.cmu.edu/~410-f10/doc/Intel_Reordering_318147.pdf>Intel® 64 Architecture Memory Ordering White Paper</a> 中的相关介绍，这里介绍其中一种。</p><p>假设最终的机器码如下，分别在两个 CPU 上执行。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>  Processor #1  |  Processor #2
</span></span><span class=line><span class=cl>----------------+----------------
</span></span><span class=line><span class=cl>  mov [X], 1    |  mov [Y], 1
</span></span><span class=line><span class=cl>  mov r1, [Y]   |  mov r2, [X]
</span></span></code></pre></div><p>上面的 r1 和 r2 分别表示 CPU 中的通用寄存器，例如 x86_64 中的 eax 。</p><p>正常来说，上述的最终结果应该是 <code>r1=1 r2=1</code> ，但实际上根据 Intel 的文档，最终的结果是可能都是 0 的。</p><p>简单来说，CPU 是允许上述的执行是乱序的，只要确保在单个线程的执行结果是正确的即可，那么也就意味着，上述的代码可以通过如下的方式执行。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>  Processor #1  |  Processor #2
</span></span><span class=line><span class=cl>----------------+----------------
</span></span><span class=line><span class=cl>  mov r1, [Y]   |
</span></span><span class=line><span class=cl>                |  mov r2, [X]
</span></span><span class=line><span class=cl>  mov [X], 1    |
</span></span><span class=line><span class=cl>                |  mov [Y], 1
</span></span></code></pre></div><a class=anchor id=测试></a><h2>测试 <a href=#%e6%b5%8b%e8%af%95 aria-hidden=true>#</a></h2><p>使用如下的代码进行测试，可以通过 <code>gcc -o order -O2 order.c -lpthread</code> 进行编译。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>#define _GNU_SOURCE
</span></span><span class=line><span class=cl>#include &lt;stdio.h&gt;
</span></span><span class=line><span class=cl>#include &lt;sched.h&gt;
</span></span><span class=line><span class=cl>#include &lt;unistd.h&gt;
</span></span><span class=line><span class=cl>#include &lt;pthread.h&gt;
</span></span><span class=line><span class=cl>#include &lt;semaphore.h&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#define USE_CPU_FENCE        0
</span></span><span class=line><span class=cl>#define USE_RAND_DELAY       0
</span></span><span class=line><span class=cl>#define USE_SINGLE_HW_THREAD 0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#define MT_IA        397
</span></span><span class=line><span class=cl>#define MT_LEN       624
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#if USE_RAND_DELAY
</span></span><span class=line><span class=cl>/* Mersenne Twister */
</span></span><span class=line><span class=cl>struct mt {
</span></span><span class=line><span class=cl>	int index;
</span></span><span class=line><span class=cl>	unsigned int buffer[MT_LEN];
</span></span><span class=line><span class=cl>};
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>unsigned int mt_integer(struct mt *mt)
</span></span><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>	// Indices
</span></span><span class=line><span class=cl>	int i1, i2, j;
</span></span><span class=line><span class=cl>	unsigned int s, r;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	i1 = mt-&gt;index;
</span></span><span class=line><span class=cl>	i2 = mt-&gt;index + 1;
</span></span><span class=line><span class=cl>	j = mt-&gt;index + MT_IA;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	if (i2 &gt;= MT_LEN)
</span></span><span class=line><span class=cl>		i2 = 0;      // wrap-around
</span></span><span class=line><span class=cl>	if (j &gt;= MT_LEN)
</span></span><span class=line><span class=cl>		j -= MT_LEN; // wrap-around
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	// Twist
</span></span><span class=line><span class=cl>	s = (mt-&gt;buffer[i1] &amp; 0x80000000) | (mt-&gt;buffer[i2] &amp; 0x7fffffff);
</span></span><span class=line><span class=cl>	r = mt-&gt;buffer[j] ^ (s &gt;&gt; 1) ^ ((s &amp; 1) * 0x9908B0DF);
</span></span><span class=line><span class=cl>	mt-&gt;buffer[mt-&gt;index] = r;
</span></span><span class=line><span class=cl>	mt-&gt;index = i2;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	// Swizzle
</span></span><span class=line><span class=cl>	r ^= (r &gt;&gt; 11);
</span></span><span class=line><span class=cl>	r ^= (r &lt;&lt; 7) &amp; 0x9d2c5680UL;
</span></span><span class=line><span class=cl>	r ^= (r &lt;&lt; 15) &amp; 0xefc60000UL;
</span></span><span class=line><span class=cl>	r ^= (r &gt;&gt; 18);
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	return r;
</span></span><span class=line><span class=cl>}
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>void mt_init(struct mt *mt, unsigned int seed)
</span></span><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>	int i;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	/*
</span></span><span class=line><span class=cl>	 * Initialize by filling with the seed, then iterating
</span></span><span class=line><span class=cl>	 * the algorithm a bunch of times to shuffle things up.
</span></span><span class=line><span class=cl>	 */
</span></span><span class=line><span class=cl>	for (i = 0; i &lt; MT_LEN; i++)
</span></span><span class=line><span class=cl>		mt-&gt;buffer[i] = seed;
</span></span><span class=line><span class=cl>	mt-&gt;index = 0;
</span></span><span class=line><span class=cl>	for (i = 0; i &lt; MT_LEN * 100; i++)
</span></span><span class=line><span class=cl>		mt_integer(mt);
</span></span><span class=line><span class=cl>}
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>sem_t begin1, begin2, end;
</span></span><span class=line><span class=cl>int X, Y;
</span></span><span class=line><span class=cl>int r1, r2;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>void *worker1_func(void *arg)
</span></span><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>	(void) arg;
</span></span><span class=line><span class=cl>#if USE_RAND_DELAY
</span></span><span class=line><span class=cl>	struct mt mt;
</span></span><span class=line><span class=cl>	mt_init(&amp;mt, 1);
</span></span><span class=line><span class=cl>#endif
</span></span><span class=line><span class=cl>	for (;;) {
</span></span><span class=line><span class=cl>		sem_wait(&amp;begin1);  // Wait for signal
</span></span><span class=line><span class=cl>#if USE_RAND_DELAY
</span></span><span class=line><span class=cl>		while (mt_integer(&amp;mt) % 8 != 0);  // Random delay
</span></span><span class=line><span class=cl>#endif
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		X = 1;
</span></span><span class=line><span class=cl>#if USE_CPU_FENCE
</span></span><span class=line><span class=cl>		asm volatile(&#34;mfence&#34; ::: &#34;memory&#34;);  // Prevent CPU reordering
</span></span><span class=line><span class=cl>#else
</span></span><span class=line><span class=cl>		asm volatile(&#34;&#34; ::: &#34;memory&#34;);  // Prevent compiler reordering
</span></span><span class=line><span class=cl>#endif
</span></span><span class=line><span class=cl>		r1 = Y;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		sem_post(&amp;end);  // Notify transaction complete
</span></span><span class=line><span class=cl>	}
</span></span><span class=line><span class=cl>	return NULL;  // Never returns
</span></span><span class=line><span class=cl>};
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>void *worker2_func(void *arg)
</span></span><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>	(void)arg;
</span></span><span class=line><span class=cl>#if USE_RAND_DELAY
</span></span><span class=line><span class=cl>	struct mt mt;
</span></span><span class=line><span class=cl>	mt_init(&amp;mt, 2);
</span></span><span class=line><span class=cl>#endif
</span></span><span class=line><span class=cl>	for (;;) {
</span></span><span class=line><span class=cl>		sem_wait(&amp;begin2);  // Wait for signal
</span></span><span class=line><span class=cl>#if USE_RAND_DELAY
</span></span><span class=line><span class=cl>		while (mt_integer(&amp;mt) % 8 != 0);  // Random delay
</span></span><span class=line><span class=cl>#endif
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		Y = 1;
</span></span><span class=line><span class=cl>#if USE_CPU_FENCE
</span></span><span class=line><span class=cl>		asm volatile(&#34;mfence&#34; ::: &#34;memory&#34;);  // Prevent CPU reordering
</span></span><span class=line><span class=cl>#else
</span></span><span class=line><span class=cl>		asm volatile(&#34;&#34; ::: &#34;memory&#34;);  // Prevent compiler reordering
</span></span><span class=line><span class=cl>#endif
</span></span><span class=line><span class=cl>		r2 = X;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		sem_post(&amp;end);  // Notify transaction complete
</span></span><span class=line><span class=cl>	}
</span></span><span class=line><span class=cl>	return NULL;  // Never returns
</span></span><span class=line><span class=cl>};
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>int main(void)
</span></span><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>	pthread_t thd1, thd2;
</span></span><span class=line><span class=cl>	int detected = 0, iterations;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	sem_init(&amp;begin1, 0, 0);
</span></span><span class=line><span class=cl>	sem_init(&amp;begin2, 0, 0);
</span></span><span class=line><span class=cl>	sem_init(&amp;end, 0, 0);
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	pthread_create(&amp;thd1, NULL, worker1_func, NULL);
</span></span><span class=line><span class=cl>	pthread_create(&amp;thd2, NULL, worker2_func, NULL);
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#if USE_SINGLE_HW_THREAD
</span></span><span class=line><span class=cl>	cpu_set_t cpus;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	CPU_ZERO(&amp;cpus);
</span></span><span class=line><span class=cl>	CPU_SET(0, &amp;cpus);
</span></span><span class=line><span class=cl>	pthread_setaffinity_np(thd1, sizeof(cpu_set_t), &amp;cpus);
</span></span><span class=line><span class=cl>	pthread_setaffinity_np(thd2, sizeof(cpu_set_t), &amp;cpus);
</span></span><span class=line><span class=cl>#endif
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	for (iterations = 1; ; iterations++) {
</span></span><span class=line><span class=cl>		X = 0;
</span></span><span class=line><span class=cl>		Y = 0;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		// Signal both threads
</span></span><span class=line><span class=cl>		sem_post(&amp;begin1);
</span></span><span class=line><span class=cl>		sem_post(&amp;begin2);
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		// Wait for both threads
</span></span><span class=line><span class=cl>		sem_wait(&amp;end);
</span></span><span class=line><span class=cl>		sem_wait(&amp;end);
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		// Check if there was a simultaneous reorder
</span></span><span class=line><span class=cl>		if (r1 == 0 &amp;&amp; r2 == 0) {
</span></span><span class=line><span class=cl>			detected++;
</span></span><span class=line><span class=cl>			printf(&#34;%d reorders detected after %d iterations\n&#34;, detected, iterations);
</span></span><span class=line><span class=cl>		}
</span></span><span class=line><span class=cl>	}
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	return 0;
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><p>如上的代码逻辑很简单，工作线程用来处理上述的逻辑，主进程进行同步以及触发。</p><p>在工作线程中，每次真正执行处理逻辑时，会添加随机的延迟，不过会导致出现乱序的概率会有效的降低，可以将其关闭之后观察。</p><p>另外，为了防止由于代码的优化导致上述的场景失效，最好检查最终生成的汇编代码。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>$ gcc -O2 -c -S ordering.c
</span></span><span class=line><span class=cl>worker1_func:
</span></span><span class=line><span class=cl>	... ...
</span></span><span class=line><span class=cl>	movl	$begin1, %edi
</span></span><span class=line><span class=cl>	call	sem_wait
</span></span><span class=line><span class=cl>	movl	$1, X(%rip)
</span></span><span class=line><span class=cl>	movl	Y(%rip), %eax
</span></span><span class=line><span class=cl>	movl	$end, %edi
</span></span><span class=line><span class=cl>	movl	%eax, r1(%rip)
</span></span><span class=line><span class=cl>	... ...
</span></span></code></pre></div><p>如上生成的是 AT&amp;T 格式的汇编，也可以通过 <code>-masm=intel</code> 参数指定是 Intel 格式。</p><p>另外需要注意的是，在所有的平台上，信号量会保持 Release 和 Require 的语义，也就是说，所有写入共享内存的在 <code>sem_post()</code> 执行后可见，而读取在 <code>sem_wait()</code> 后可见。</p><p>在这里，也就意味着，在工作线程中，可以确保 <code>X=0 Y=0</code> 在真正执行处理逻辑前已经同步，而结果在执行完之后对所有线程可见。</p><p>如下是在 CentOS 上的执行结果。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>$ ./ordering
</span></span><span class=line><span class=cl>1 reorders detected after 57768 iterations
</span></span><span class=line><span class=cl>2 reorders detected after 101070 iterations
</span></span><span class=line><span class=cl>3 reorders detected after 130491 iterations
</span></span><span class=line><span class=cl>4 reorders detected after 130766 iterations
</span></span><span class=line><span class=cl>5 reorders detected after 135479 iterations
</span></span><span class=line><span class=cl>6 reorders detected after 142153 iterations
</span></span><span class=line><span class=cl>... ...
</span></span></code></pre></div><a class=anchor id=解决方案></a><h2>解决方案 <a href=#%e8%a7%a3%e5%86%b3%e6%96%b9%e6%a1%88 aria-hidden=true>#</a></h2><p>最简单的，可以将两个线程绑定到同一个核中，这是因为在同一个核中不会出现乱序，即使多个线程在循环的调度执行。</p><p>另外，也可以添加一个 Barrier 防止乱序，这里解决的是 Store 之后做 Load 操作，也就是 StoreLoad Barrier ，不过在 Intel 中 <code>mfence</code> 会防止所有的乱序出现。</p><a class=anchor id=内存屏障></a><h1>内存屏障 <a href=#%e5%86%85%e5%ad%98%e5%b1%8f%e9%9a%9c aria-hidden=true>#</a></h1><p>这里所谓的内存屏障实际上主要是 CPU 提供的方式，包括了防止 CPU 乱序，Cache 的更新操作。</p><p>内存操作涉及到了 Load 和 Store 两个，那么两两组合之后可能会出现四种方式的乱序，通过某些 Barriers 可以防止这种乱序。总共有 <code>LoadLoad</code> <code>LoadStore</code> <code>StoreLoad</code> <code>StoreStore</code> 四种。</p><p><img alt="barrier types" src=images/barrier-types.png class="mx-auto d-block"></p><p>这里，直接通过出现乱序的方式标识，例如 StoreLoad 是为了防止出现 Store 跟着 Load 的乱序。</p><p>注意，对于真实的 CPU 来说，上述的四种类型并非都会出现。</p><p>内存屏障有两个作用：A) 防止指令发生重排；B) 使缓存中的数据失效。可以通过如下方式简单理解最简单的 Load Store 屏障：</p><ol><li>在指令前插入 Load Barrier 可以让高速缓存中的数据失效，强制从新从主内存加载数据；</li><li>在指令后插入 Store Barrier 能让写入缓存中的最新数据更新写入主内存，让其它线程可见。</li></ol><a class=anchor id=loadload></a><h3>LoadLoad <a href=#loadload aria-hidden=true>#</a></h3><p>假设有如下的操作 <code>Load1; LoadLoad; Load2</code>，在 Load2 及后续读取操作要读取的数据被访问前，保证 Load1 要读取的数据被读取完毕。</p><p>例如，如下的代码。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>if (IsPublished)               // Load and check shared flag
</span></span><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>	LOADLOAD_FENCE();      // Prevent reordering of loads
</span></span><span class=line><span class=cl>	return Value;          // Load published value
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><p>这里实际并不关心 <code>IsPublished</code> 何时被设置为非 1 ，但是一旦改标志位被设置了，那么就需要通过 LoadLoad 栅栏，确保 Value 的值不会比 IsPublished 更老。</p><p>也就是说，此时读取到的 IsPublished 值不一定是最新的，但是一旦读取到了，那么就需要保证 Value 的值不能老于 IsPublished 的值。</p><a class=anchor id=storestore></a><h3>StoreStore <a href=#storestore aria-hidden=true>#</a></h3><p>对于如下的操作 <code>Store1; StoreStore; Store2</code>，在 Store2 及后续写入操作执行前，保证 Store1 的写入操作对其它处理器可见。</p><p>例如，对于如下的代码。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Value = x;                     // Publish some data
</span></span><span class=line><span class=cl>STORESTORE_FENCE();
</span></span><span class=line><span class=cl>IsPublished = 1;               // Set shared flag to indicate availability of data
</span></span></code></pre></div><p>这里确保的是，在设置 IsPublished 为 1 后，之前关于 Value 的修改已经对其它处理器可见，这里的 Value 可以是一个原子操作，也可以是一个结构体。</p><a class=anchor id=loadstore></a><h3>LoadStore <a href=#loadstore aria-hidden=true>#</a></h3><p>假设有操作 <code>Load1; LoadStore; Store2</code>，通过屏障可以确保，在 Store2 及后续写入操作被刷出前，保证 Load1 要读取的数据被读取完毕。</p><p>真实的 CPU 中，可能 Load1 发生了 Cache Miss ，而 Store2 是 Cache Hit 那么就可能导致 Store2 要早于 Load1 执行，那么就需要屏障保证执行顺序。</p><p>实际 CPU 中的实现，实际上也就是 LoadLoad 和 StoreStore 其中之一。</p><a class=anchor id=storeload></a><h3>StoreLoad <a href=#storeload aria-hidden=true>#</a></h3><p>对于操作 <code>Store1; StoreLoad; Load2</code>，在 Load2 以及后续所有读取操作执行前，保证 Store1 的写入对所有处理器可见。</p><p>也就是说，对于 StoreLoad 屏障来说，会确保屏障前所有的 Store 对其它处理器可见，而且屏障之后会将所有在屏障时的更新对处理器可见。</p><p>换言之，这个屏障保证了屏障前的所有 Store 操作不会发生在屏障之后的所有 Load 操作之后，因此符合符合顺序一致性。</p><p>可以简单理解为，StoreLoad 首先将所有最近的局部修改更新到所有处理器，然后等更新完成后，再将所有的更新拉取到本地。</p><p>这也是做同步时，成本消耗最高的。</p><a class=anchor id=总结></a><h3>总结 <a href=#%e6%80%bb%e7%bb%93 aria-hidden=true>#</a></h3><p>一般来说，Store 的成本要高于 Load 操作的成本，所以导致很多的编译器、CPU 等，当 Load 操作与 Store 操作不相关时，一般会将 Store 操作提前，以优化性能。</p><p>其中 StoreLoad 的屏障粒度是最大的，在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。但是，即使有了其它的三个屏障，仍然无法解决之前乱序可能出现的 <code>r1=r2=0</code> 的问题。</p><p>也即是说，StoreLoad 屏障，是唯一可以解决 <code>r1=r2=0</code> 乱序的方式。</p><a class=anchor id=其它></a><h1>其它 <a href=#%e5%85%b6%e5%ae%83 aria-hidden=true>#</a></h1><a class=anchor id=cpu-memory-barrier></a><h2>CPU Memory Barrier <a href=#cpu-memory-barrier aria-hidden=true>#</a></h2><p>理论上来说，对于不同的硬件内存模型，可能产生的内存乱序的种类并不相同 (实际上，主要是由于 Write Buffer 的存在而产生)。</p><p>按照 Load+Store 的四种排列方式，也就是四种不同的 CPU 内存乱序，也应该存在对应的四种 barrier。然而针对 Intel CPU 而言，主要有三种内存 Barrier 。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Store Barrier   确保 Barrier 前后的 store 操作不会发生乱序;
</span></span><span class=line><span class=cl>Load Barrier    确保 Barrier 前后的 load 操作不会发生乱序;
</span></span><span class=line><span class=cl>Full Barrier    确保 Barrier 前后的内存操作不会发生乱序;
</span></span></code></pre></div><p>可以通过 CPU 提供的如下的指令来显示的达到 Barrier 的目的：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#define STORE_BARRIER() __asm__ __volatile__(&#34;sfence&#34;)
</span></span></span><span class=line><span class=cl><span class=cp>#define LOAD_BARRIER() __asm__ __volatile__(&#34;lfence&#34;)
</span></span></span><span class=line><span class=cl><span class=cp>#define FULL_BARRIER() __asm__ __volatile__(&#34;mfence&#34;)
</span></span></span></code></pre></div><p>同时，任何带有 lock 操作的指令以及某些原子操作指令均可以当做隐式的 Barrier，例如：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>__asm__</span> <span class=nf>__volatile__</span><span class=p>(</span><span class=s>&#34;lock; addl $0,0(%%esp)&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>__asm__</span> <span class=nf>__volatile__</span><span class=p>(</span><span class=s>&#34;xchgl (%0)</span><span class=p>,</span><span class=o>%</span><span class=mi>0</span><span class=s>&#34;)</span><span class=p>;</span>
</span></span></code></pre></div><p>也可以将 Compiler Barrier 和 CPU Barrier 通过一条指令来实现：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#define ONE_BARRIER() __asm__ __volatile__(&#34;mfence&#34;:::&#34;memory&#34;)
</span></span></span></code></pre></div><p>最后需要说明的是，不同于编译屏障，CPU 内存屏障是在 CPU 上执行的指令，任何在程序中定义的 CPU 屏障最后都会编译成为汇编代码中的指令，例如，使用上面的 <code>LOAD_BARRIER()</code> 会在汇编代码中相应的位置插入 <code>lfence</code> 指令。</p><a class=anchor id=跨平台></a><h2>跨平台 <a href=#%e8%b7%a8%e5%b9%b3%e5%8f%b0 aria-hidden=true>#</a></h2><p>如上的 <code>mfence</code> 是 x86_64 中使用的，那么对于其它平台可能是不同的指令，所以像 Linux 内核中，会通过 <code>smp_rmb()</code> <code>smp_wmb()</code> <code>smp_mb()</code> 来适配不同的平台。</p><a class=anchor id=参考></a><h1>参考 <a href=#%e5%8f%82%e8%80%83 aria-hidden=true>#</a></h1><ul><li><a href=https://software.intel.com/en-us/articles/intel-sdm>Intel® 64 and IA-32 Architectures Software Developer Manuals</a> x86 的编程手册。</li><li><a href=https://preshing.com/20120930/weak-vs-strong-memory-models/>Weak vs. Strong Memory Models</a> 对于 Weak 和 Strong 类型的总结。</li></ul></div></div><div class="sidebar col-xl-3 mt-2"><div id=toc class=position-fixed><nav id=TableOfContents><ul><li><a href=#简介>简介</a></li><li><a href=#编译乱序>编译乱序</a><ul><li><a href=#防止乱序>防止乱序</a></li></ul></li><li><a href=#cpu-乱序>CPU 乱序</a><ul><li><a href=#测试>测试</a></li><li><a href=#解决方案>解决方案</a></li></ul></li><li><a href=#内存屏障>内存屏障</a><ul><li></li></ul></li><li><a href=#其它>其它</a><ul><li><a href=#cpu-memory-barrier>CPU Memory Barrier</a></li><li><a href=#跨平台>跨平台</a></li></ul></li><li><a href=#参考>参考</a></li></ul></nav></div></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class=text-center>Built by GoHalo, generated with <a class=text-muted href=https://gohugo.io>Hugo</a>, and hosted on GitHub Pages</div></div><div class=row><div class=text-center>Copyright © 2013-2025 GoHalo. All Rights Reserved.</div></div></div></footer><script src=https://gohalo.github.io/bootstrap/js/bootstrap.bundle.min.js></script>
<script src=/main.b9cbcb174709877512d64e24f297f66a40c8d91c9a81128cb04bdd7b10247df8.js integrity="sha256-ucvLF0cJh3US1k4k8pf2akDI2RyagRKMsEvdexAkffg=" crossorigin=anonymous></script>
<a href=# class="btn btn-light btn-lg backtop" title=返回顶部><i class="fa fa-angle-double-up" aria-hidden=true></i></a></body></html>